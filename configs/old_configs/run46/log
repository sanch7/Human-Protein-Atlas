(pytorch) litemax@litemax-hub:~/kaggle/Human-Protein-Atlas$ python train.py
Loaded configuration from  ./configs/config.json

{'batch_size': 16,
 'cosine_annealing': False,
 'desc': 'inceptionv4, focal loss gamma = 2',
 'drop_rate': 0,
 'epochs': 200,
 'exp_name': 'run46',
 'external_data': True,
 'focal_gamma': 2,
 'fp16': False,
 'imsize': 512,
 'lr': 0.001,
 'lr_patience': 3,
 'lr_scale': 0.1,
 'mixup': False,
 'model_name': 'inceptionv4',
 'num_channels': 4,
 'num_workers': 6,
 'preload_data': False,
 'pretrained': True,
 'reduce_lr_plateau': True,
 'test_size': 0.2}

Using Inception v4
Loading weights...
Focal Loss with gamma =  2
Training ...
Saving to  ./model_weights/best_inceptionv4_run46.pth

Epoch 0/200
B: 6217/6217 | Loss: 1.1140  | ETA:    0s
Avg Train Loss: 1.337
B: 389/389 | ETA:    0s
Avg Eval Loss: 2.489, Avg Eval Macro F1: 0.03643, Avg Eval Acc. 0.9449
Best val loss achieved. loss = 2.4893.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4791s

Epoch 1/200
B: 6217/6217 | Loss: 1.5488  | ETA:    0s
Avg Train Loss: 1.154
B: 389/389 | ETA:    0s
Avg Eval Loss: 9.461, Avg Eval Macro F1: 0.04634, Avg Eval Acc. 0.9444
Time: 4765s

Epoch 2/200
B: 6217/6217 | Loss: 0.7105  | ETA:    0s
Avg Train Loss: 1.089
B: 389/389 | ETA:    0s
Avg Eval Loss: 2.988, Avg Eval Macro F1: 0.09854, Avg Eval Acc. 0.9398
Time: 4780s

Epoch 3/200
B: 6217/6217 | Loss: 0.5935  | ETA:    0s
Avg Train Loss: 0.9994
B: 389/389 | ETA:    0s
Avg Eval Loss: 1.158, Avg Eval Macro F1: 0.1487, Avg Eval Acc. 0.9529
Best val loss achieved. loss = 1.1577.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4781s

Epoch 4/200
B: 6217/6217 | Loss: 0.8264  | ETA:    0s
Avg Train Loss: 0.9445
B: 389/389 | ETA:    0s
Avg Eval Loss: 1.074, Avg Eval Macro F1: 0.1764, Avg Eval Acc. 0.9546
Best val loss achieved. loss = 1.0741.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4783s

Epoch 5/200
B: 6217/6217 | Loss: 1.0596  | ETA:    0s
Avg Train Loss: 0.9033
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.9197, Avg Eval Macro F1: 0.2289, Avg Eval Acc. 0.9578
Best val loss achieved. loss = 0.9197.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4789s

Epoch 6/200
B: 6217/6217 | Loss: 1.0506  | ETA:    0s
Avg Train Loss: 0.8646
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.9784, Avg Eval Macro F1: 0.2515, Avg Eval Acc. 0.9549
Time: 4787s

Epoch 7/200
B: 6217/6217 | Loss: 0.7311  | ETA:    0s
Avg Train Loss: 0.8382
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.8717, Avg Eval Macro F1: 0.3157, Avg Eval Acc. 0.9603
Best val loss achieved. loss = 0.8717.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4789s

Epoch 8/200
B: 6217/6217 | Loss: 1.1390  | ETA:    0s
Avg Train Loss: 0.8198
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.8555, Avg Eval Macro F1: 0.3085, Avg Eval Acc. 0.9621
Best val loss achieved. loss = 0.8555.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4793s

Epoch 9/200
B: 6217/6217 | Loss: 1.2579  | ETA:    0s
Avg Train Loss: 0.8022
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.8791, Avg Eval Macro F1: 0.3544, Avg Eval Acc. 0.959
Time: 4804s

Epoch 10/200
B: 6217/6217 | Loss: 1.2413  | ETA:    0s
Avg Train Loss: 0.7885
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.787, Avg Eval Macro F1: 0.3667, Avg Eval Acc. 0.9637
Best val loss achieved. loss = 0.7870.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4808s

Epoch 11/200
B: 6217/6217 | Loss: 1.5570  | ETA:    0s
Avg Train Loss: 0.7779
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.771, Avg Eval Macro F1: 0.3951, Avg Eval Acc. 0.9646
Best val loss achieved. loss = 0.7710.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4803s

Epoch 12/200
B: 6217/6217 | Loss: 0.5162  | ETA:    0s
Avg Train Loss: 0.7696
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7549, Avg Eval Macro F1: 0.4058, Avg Eval Acc. 0.9652
Best val loss achieved. loss = 0.7549.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4789s

Epoch 13/200
B: 6217/6217 | Loss: 0.9453  | ETA:    0s
Avg Train Loss: 0.7595
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7551, Avg Eval Macro F1: 0.4039, Avg Eval Acc. 0.9648
Time: 4791s

Epoch 14/200
B: 6217/6217 | Loss: 0.8391  | ETA:    0s
Avg Train Loss: 0.7497
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7309, Avg Eval Macro F1: 0.4346, Avg Eval Acc. 0.9663
Best val loss achieved. loss = 0.7309.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4789s

Epoch 15/200
B: 6217/6217 | Loss: 0.6011  | ETA:    0s
Avg Train Loss: 0.7457
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7512, Avg Eval Macro F1: 0.4045, Avg Eval Acc. 0.9662
Time: 4781s

Epoch 16/200
B: 6217/6217 | Loss: 0.5993  | ETA:    0s
Avg Train Loss: 0.7392
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7386, Avg Eval Macro F1: 0.4798, Avg Eval Acc. 0.9661
Time: 4789s

Epoch 17/200
B: 6217/6217 | Loss: 1.1244  | ETA:    0s
Avg Train Loss: 0.7324
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7488, Avg Eval Macro F1: 0.4263, Avg Eval Acc. 0.9652
Time: 4785s

Epoch 18/200
B: 6217/6217 | Loss: 0.6194  | ETA:    0s
Avg Train Loss: 0.7254
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6925, Avg Eval Macro F1: 0.4801, Avg Eval Acc. 0.968
Best val loss achieved. loss = 0.6925.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4797s

Epoch 19/200
B: 6217/6217 | Loss: 0.5000  | ETA:    0s
Avg Train Loss: 0.7218
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7495, Avg Eval Macro F1: 0.4259, Avg Eval Acc. 0.9656
Time: 4799s

Epoch 20/200
B: 6217/6217 | Loss: 0.5698  | ETA:    0s
Avg Train Loss: 0.7157
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.8461, Avg Eval Macro F1: 0.4461, Avg Eval Acc. 0.9647
Time: 4802s

Epoch 21/200
B: 6217/6217 | Loss: 1.2050  | ETA:    0s
Avg Train Loss: 0.7105
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.8476, Avg Eval Macro F1: 0.4469, Avg Eval Acc. 0.9636
Time: 4810s

Epoch 22/200
B: 6217/6217 | Loss: 1.0394  | ETA:    0s
Avg Train Loss: 0.7058
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.7043, Avg Eval Macro F1: 0.5172, Avg Eval Acc. 0.9666
Epoch    22: reducing learning rate of group 0 to 1.0000e-04.
Time: 4805s

Epoch 23/200
B: 6217/6217 | Loss: 0.6763  | ETA:    0s
Avg Train Loss: 0.6698
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6168, Avg Eval Macro F1: 0.5663, Avg Eval Acc. 0.9712
Best val loss achieved. loss = 0.6168.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4799s

Epoch 24/200
B: 6217/6217 | Loss: 0.5380  | ETA:    0s
Avg Train Loss: 0.6613
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6169, Avg Eval Macro F1: 0.5535, Avg Eval Acc. 0.9713
Time: 4947s

Epoch 25/200
B: 6217/6217 | Loss: 0.3322  | ETA:    0s
Avg Train Loss: 0.6559
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6235, Avg Eval Macro F1: 0.579, Avg Eval Acc. 0.9715
Time: 4799s

Epoch 26/200
B: 6217/6217 | Loss: 1.0541  | ETA:    0s
Avg Train Loss: 0.6533
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6063, Avg Eval Macro F1: 0.5568, Avg Eval Acc. 0.9716
Best val loss achieved. loss = 0.6063.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4795s

Epoch 27/200
B: 6217/6217 | Loss: 1.1343  | ETA:    0s
Avg Train Loss: 0.6543
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6042, Avg Eval Macro F1: 0.5846, Avg Eval Acc. 0.9717
Best val loss achieved. loss = 0.6042.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4951s

Epoch 28/200
B: 6217/6217 | Loss: 0.7564  | ETA:    0s
Avg Train Loss: 0.6509
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6189, Avg Eval Macro F1: 0.5637, Avg Eval Acc. 0.9708
Time: 4949s

Epoch 29/200
B: 6217/6217 | Loss: 0.5508  | ETA:    0s
Avg Train Loss: 0.6499
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6115, Avg Eval Macro F1: 0.5792, Avg Eval Acc. 0.9716
Time: 4883s

Epoch 30/200
B: 6217/6217 | Loss: 0.7134  | ETA:    0s
Avg Train Loss: 0.6485
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6037, Avg Eval Macro F1: 0.5839, Avg Eval Acc. 0.9719
Best val loss achieved. loss = 0.6037.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4736s

Epoch 31/200
B: 6217/6217 | Loss: 0.6165  | ETA:    0s
Avg Train Loss: 0.6485
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6115, Avg Eval Macro F1: 0.587, Avg Eval Acc. 0.9713
Time: 4716s

Epoch 32/200
B: 6217/6217 | Loss: 0.6190  | ETA:    0s
Avg Train Loss: 0.6454
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6007, Avg Eval Macro F1: 0.5868, Avg Eval Acc. 0.9718
Best val loss achieved. loss = 0.6007.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4712s

Epoch 33/200
B: 6217/6217 | Loss: 1.0159  | ETA:    0s
Avg Train Loss: 0.6457
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6032, Avg Eval Macro F1: 0.5763, Avg Eval Acc. 0.9716
Time: 4714s

Epoch 34/200
B: 6217/6217 | Loss: 0.7384  | ETA:    0s
Avg Train Loss: 0.6438
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6043, Avg Eval Macro F1: 0.5783, Avg Eval Acc. 0.9717
Time: 4715s

Epoch 35/200
B: 6217/6217 | Loss: 0.6622  | ETA:    0s
Avg Train Loss: 0.6426
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.6046, Avg Eval Macro F1: 0.596, Avg Eval Acc. 0.972
Time: 4716s

Epoch 36/200
B: 6217/6217 | Loss: 0.7481  | ETA:    0s
Avg Train Loss: 0.6407
B: 389/389 | ETA:    0s
Avg Eval Loss: 0.5951, Avg Eval Macro F1: 0.5778, Avg Eval Acc. 0.972
Best val loss achieved. loss = 0.5951.  Saving model to  ./model_weights/best_inceptionv4_run46.pth
Time: 4733s

Epoch 37/200
^CB: 508/6217 | Loss: 0.5030  | ETA: 4272s

Generate submission while the GPU is still hot from training? [Y/n]: n
(pytorch) litemax@litemax-hub:~/kaggle/Human-Protein-Atlas$ python make_submission.py 
Loaded configuration from  ./configs/config.json

{'batch_size': 16,
 'cosine_annealing': False,
 'desc': 'inceptionv4, focal loss gamma = 2',
 'drop_rate': 0,
 'epochs': 200,
 'exp_name': 'run46',
 'external_data': True,
 'focal_gamma': 2,
 'fp16': False,
 'imsize': 512,
 'lr': 0.001,
 'lr_patience': 3,
 'lr_scale': 0.1,
 'mixup': False,
 'model_name': 'inceptionv4',
 'num_channels': 4,
 'num_workers': 6,
 'preload_data': False,
 'pretrained': True,
 'reduce_lr_plateau': True,
 'test_size': 0.2}

Using Inception v4
Loading model from ./model_weights/best_inceptionv4_run46.pth
Generating predictions...
B: 732/732 | ETA:    0s
Generating submission with class wise thresholding...
Finding best threshold...
B: 1942/1942 | ETA:    0s
Best Thresholds:  [-0.15  0.1  -0.15 -0.35 -0.4  -0.25 -0.2  -0.25 -0.25 -0.75 -0.45 -0.3
 -0.5  -0.25 -0.15 -0.95 -0.35  0.2  -0.45 -0.45 -0.75 -0.3  -0.5  -0.3
 -0.35 -0.3  -0.45 -1.3 ]
Best Eval Macro F1:  [0.85525977 0.85912617 0.8135832  0.75862069 0.80641593 0.7130064
 0.63437999 0.81510417 0.71287129 0.75555556 0.72727273 0.73930348
 0.66405638 0.65833333 0.87753134 0.48484848 0.41291585 0.36931818
 0.55378281 0.65693904 0.44192635 0.68004573 0.59963658 0.83165916
 0.70642202 0.71089844 0.50764526 0.03571429]
Best Eval Macro F1 Avg:  0.6565061646202947
Saved to  ./subm/best_inceptionv4_run46.csv
Saved to  ./subm/best_inceptionv4_run46_m_b.csv
