{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1005
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 174333,
     "status": "ok",
     "timestamp": 1538680596075,
     "user": {
      "displayName": "Daniel Borders",
      "photoUrl": "",
      "userId": "03898444674615005606"
     },
     "user_tz": 300
    },
    "id": "eNqJmaFsRhlS",
    "outputId": "182808d1-e679-4489-da1a-00b6a690236a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/login1/anaconda2/lib/python2.7/site-packages (0.4.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torchvision in /home/login1/anaconda2/lib/python2.7/site-packages/torchvision-0.2.1-py2.7.egg (0.2.1)\n",
      "Requirement already satisfied: numpy in /home/login1/anaconda2/lib/python2.7/site-packages (from torchvision) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/login1/anaconda2/lib/python2.7/site-packages (from torchvision) (5.0.0)\n",
      "Requirement already satisfied: six in /home/login1/anaconda2/lib/python2.7/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: torch in /home/login1/anaconda2/lib/python2.7/site-packages (from torchvision) (0.4.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /home/login1/anaconda2/lib/python2.7/site-packages (4.28.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install pytorch and tqdm (if necessary)\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30890,
     "status": "ok",
     "timestamp": 1538680781417,
     "user": {
      "displayName": "Daniel Borders",
      "photoUrl": "",
      "userId": "03898444674615005606"
     },
     "user_tz": 300
    },
    "id": "wA4n2ZsKP-dt",
    "outputId": "18c01c75-5642-4179-b845-6539a31106ab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3Hu3-dhIaga"
   },
   "outputs": [],
   "source": [
    "# Handle imports\n",
    "\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7cF6oVvIesG"
   },
   "outputs": [],
   "source": [
    "# The Args object will contain all of our parameters\n",
    "# If you want to run with different arguments, create another Args object\n",
    "\n",
    "class Args(object):\n",
    "  def __init__(self, name='mnist', batch_size=64, test_batch_size=1000,\n",
    "            epochs=10, lr=0.01, optimizer='sgd', momentum=0.5,\n",
    "            seed=1, log_interval=100, dataset='mnist',\n",
    "            data_dir='Data/', model='default',\n",
    "            cuda=True):\n",
    "    self.name = name # name for this training run. Don't use spaces.\n",
    "    self.batch_size = batch_size\n",
    "    self.test_batch_size = test_batch_size # Input batch size for testing\n",
    "    self.epochs = epochs # Number of epochs to train\n",
    "    self.lr = lr # Learning rate\n",
    "    self.optimizer = optimizer # sgd/p1sgd/adam/rms_prop\n",
    "    self.momentum = momentum # SGD Momentum\n",
    "    self.seed = seed # Random seed\n",
    "    self.log_interval = log_interval # Batches to wait before logging\n",
    "                                     # detailed status. 0 = never\n",
    "    self.data_dir = data_dir\n",
    "    self.model = model # default/P2Q7DoubleChannelsNet/P2Q7HalfChannelsNet/\n",
    "                  # P2Q8BatchNormNet/P2Q9DropoutNet/P2Q10DropoutBatchnormNet/\n",
    "                  # P2Q11ExtraConvNet/P2Q12RemoveLayerNet/P2Q13UltimateNet\n",
    "    self.cuda = cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTdCE87lIjtK"
   },
   "outputs": [],
   "source": [
    "# Define the neural network classes\n",
    "\n",
    "class Experiment1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Experiment1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 96, kernel_size=11, stride=4, padding=(5,5))\n",
    "        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=(2,2))\n",
    "        self.convM = nn.Conv2d(256, 256, kernel_size=3, padding=(1,1))\n",
    "        self.conv3 = nn.Conv2d(256, 384, kernel_size=3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=(1,1))\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16384, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 28)#because there are 28 possibe outputs\n",
    "\n",
    "    def forward(self, x):\n",
    "        # F is just a functional wrapper for modules from the nn package\n",
    "        # see http://pytorch.org/docs/_modules/torch/nn/functional.html\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.convM(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv5(x), 2))\n",
    "        x = x.view(-1, 16384)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(self.fc3(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 124288\n",
      "torch.Size([10, 4, 512, 512])\n",
      "torch.Size([10, 28])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import csv\n",
    "trainList = os.listdir(\"Data/train/\")\n",
    "length = len(trainList)\n",
    "print(\"Loaded: \" + str(lenght))\n",
    "with open(\"Data/train.csv\") as csvfile:\n",
    "    csvFile = csv.reader(csvfile)\n",
    "    dictionary = {rows[0]:rows[1] for rows in csvFile}\n",
    "def generateBatch(num):\n",
    "    x_out_fin = torch.zeros((num,4,512,512))\n",
    "    y_out_fin = torch.zeros((num, 28))\n",
    "    for i in range(num):\n",
    "        rdir = random.randrange(length)\n",
    "        id, suff = trainList[rdir].split('_')\n",
    "        suffix = \"Data/train/\"\n",
    "        red = cv2.imread(suffix+id+\"_red.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        yellow = cv2.imread(suffix+id+\"_yellow.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        green = cv2.imread(suffix+id+\"_green.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        blue = cv2.imread(suffix+id+\"_blue.png\", cv2.IMREAD_GRAYSCALE)\n",
    "        x = np.zeros((4,red.shape[0], red.shape[1]))\n",
    "        x[0,:,:]=red\n",
    "        x[1,:,:]=yellow\n",
    "        x[2,:,:]=green\n",
    "        x[3,:,:]=blue\n",
    "        x_out = torch.from_numpy(x)\n",
    "        x_out_fin[i,:,:,:]=x_out\n",
    "        if id in dictionary:\n",
    "            cats = dictionary[id].split(\" \")\n",
    "            for ndx in cats:\n",
    "                y_out_fin[i, int(ndx)] = 1\n",
    "                \n",
    "    return x_out_fin, y_out_fin\n",
    "\n",
    "a,b = generateBatch(10)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2Ejw36nIpRr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6625,
     "status": "ok",
     "timestamp": 1538680961129,
     "user": {
      "displayName": "Daniel Borders",
      "photoUrl": "",
      "userId": "03898444674615005606"
     },
     "user_tz": 300
    },
    "id": "AVGaeczNItaS",
    "outputId": "6a21053c-9523-403c-e678-0f0ce5c102e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABNCAYAAAAFKbeYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdeb9ba1c18>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize some images\n",
    "\n",
    "args = Args(dataset='fashion_mnist')\n",
    "_, _, _, test_dataset, _ = prepare_dataset(args)\n",
    "images = test_dataset.test_data[:6]\n",
    "print(images.shape)\n",
    "labels = test_dataset.test_labels[:6]\n",
    "fig, axes = plt.subplots(1,6)\n",
    "for axis, img, lbl in zip(axes, images, labels):\n",
    "    axis.imshow(img)\n",
    "    axis.set_title(lbl)\n",
    "    axis.set_yticklabels([])\n",
    "    axis.set_xticklabels([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tD-StYJ2I6u2"
   },
   "outputs": [],
   "source": [
    "def train(args, model, optimizer, epoch, total_minibatch_count,\n",
    "        train_losses, train_accs):\n",
    "    # Training for a full epoch\n",
    "    num_iterations = int(length/args.batch_size)\n",
    "    model.train()\n",
    "    correct_count, total_loss, total_acc = 0., 0., 0.\n",
    "    print_current = int(num_iterations/10)\n",
    "    for batch_idx in range(num_iterations):\n",
    "        \n",
    "        data, target = generateBatch(args.batch_size)\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward prediction step\n",
    "        output = model(data)\n",
    "        test = torch.nn.MultiLabelSoftMarginLoss()\n",
    "        loss = test(output, target)\n",
    "        \n",
    "        if(batch_idx % print_current == 0):\n",
    "            print(str(batch_idx) + \"/\" + str(num_iterations))\n",
    "            print(loss)\n",
    "            print(\"OUTPUT\")\n",
    "            print(output[0:5])\n",
    "            print(\"TARGET\")\n",
    "            print(target[0:5])\n",
    "            print(\"^\"*70)\n",
    "\n",
    "        # Backpropagation step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # The batch has ended, determine the accuracy of the predicted outputs\n",
    "        \n",
    "        #pred = output.data.max(1)[1]  \n",
    "\n",
    "        # target labels and predictions are categorical values from 0 to 9.\n",
    "        #matches = target == pred\n",
    "        #accuracy = matches.float().mean()\n",
    "        #correct_count += matches.sum()\n",
    "\n",
    "        if args.log_interval != 0 and \\\n",
    "                total_minibatch_count % args.log_interval == 0:\n",
    "\n",
    "            train_losses.append(loss.data[0])\n",
    "            #train_accs.append(accuracy.data[0])\n",
    "            \n",
    "        total_loss += loss.data\n",
    "        #total_acc += accuracy.data\n",
    "           \n",
    "\n",
    "        total_minibatch_count += 1\n",
    "\n",
    "    return total_minibatch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgCLKEHcI-bg"
   },
   "outputs": [],
   "source": [
    "def test(args, model, epoch, total_minibatch_count,\n",
    "        val_losses, val_accs):\n",
    "    # Validation Testing\n",
    "    model.eval()\n",
    "    test_loss, correct = 0., 0.\n",
    "    validation_thing = generateBatch(args.test_batch_size)\n",
    "    with torch.no_grad():\n",
    "        for current_sample in validation_thing:\n",
    "            data,target = validation_thing[current_sample]\n",
    "            if args.cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test = torch.nn.MultiLabelSoftMarginLoss()\n",
    "            test_loss += test(output, target, reduction='sum').data  # sum up batch loss\n",
    "            #pred = output.data.max(1)[1]  # get the index of the max log-probability\n",
    "            #correct += (target == pred).float().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    val_losses.append(test_loss)\n",
    "    #val_accs.append(acc)\n",
    "    \n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khV-_vFSJGT8"
   },
   "outputs": [],
   "source": [
    "# Run the experiment\n",
    "def run_experiment(args):\n",
    "\n",
    "    total_minibatch_count = 0\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "    epochs_to_run = args.epochs\n",
    "\n",
    "    # Choose model\n",
    "    # TODO add all the other models here if their parameter is specified\n",
    "    if args.model == 'default' or args.model == 'P2Q7DefaultChannelsNet':\n",
    "        model = Experiment1()\n",
    "    elif args.model in globals():\n",
    "        model = globals()[args.model]()\n",
    "    else:\n",
    "        raise ValueError('Unknown model type: ' + args.model)\n",
    "\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    # Choose optimizer\n",
    "    if args.optimizer == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    elif args.optimizer == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "    elif args.optimizer == 'rms_prop':\n",
    "        optimizer = optim.RMSprop(model.parameters())\n",
    "    else:\n",
    "        raise ValueError('Unsupported optimizer: ' + args.optimizer)\n",
    "\n",
    "    # Run the primary training loop, starting with validation accuracy of 0\n",
    "    val_acc = 0\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    for epoch in range(1, epochs_to_run + 1):\n",
    "        print(str(epoch) + \"/\" + str(epochs_to_run + 1))\n",
    "        \n",
    "        # train for 1 epoch\n",
    "        total_minibatch_count = train(args, model, optimizer,\n",
    "                                    epoch, total_minibatch_count,\n",
    "                                    train_losses, train_accs)\n",
    "        # validate progress on test dataset\n",
    "        val_acc = test(args, model, epoch, total_minibatch_count,\n",
    "                       val_losses, val_accs)\n",
    "        \n",
    "    fig, axes = plt.subplots(1,4, figsize=(13,4))\n",
    "    # plot the losses and acc\n",
    "    plt.title(args.name)\n",
    "    axes[0].plot(train_losses)\n",
    "    axes[0].set_title(\"Loss\")\n",
    "    axes[1].plot(train_accs)\n",
    "    axes[1].set_title(\"Acc\")\n",
    "    axes[2].plot(val_losses)\n",
    "    axes[2].set_title(\"Val loss\")\n",
    "    axes[3].plot(val_accs)\n",
    "    axes[3].set_title(\"Val Acc\")\n",
    "    \n",
    "    # Write to csv file\n",
    "    with open(os.path.join(run_path + 'train.csv'), 'w') as f:\n",
    "        csvw = csv.writer(f, delimiter=',')\n",
    "        for loss, acc in zip(train_losses, train_accs):\n",
    "            csvw.writerow((loss, acc))\n",
    "\n",
    "    # Predict and Test\n",
    "    images, labels = next(iter(test_loader))\n",
    "    if args.cuda:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "    output = model(images)\n",
    "    predicted = torch.max(output, 1)[1]\n",
    "    fig, axes = plt.subplots(1,6)\n",
    "    for i, (axis, img, lbl) in enumerate(zip(axes, images, predicted)):\n",
    "        if i > 5:\n",
    "            break\n",
    "        img = img.permute(1,2,0).squeeze()\n",
    "        axis.imshow(img)\n",
    "        axis.set_title(lbl.data)\n",
    "        axis.set_yticklabels([])\n",
    "        axis.set_xticklabels([])\n",
    "            \n",
    "    if args.dataset == 'fashion_mnist' and val_acc > 0.92 and val_acc <= 1.0:\n",
    "        print(\"Congratulations, you beat the Question 13 minimum of 92\"\n",
    "            \"with ({:.2f}%) validation accuracy!\".format(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1091
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243490,
     "status": "ok",
     "timestamp": 1538685403453,
     "user": {
      "displayName": "Daniel Borders",
      "photoUrl": "",
      "userId": "03898444674615005606"
     },
     "user_tz": 300
    },
    "id": "OQ6ztrNWJKmm",
    "outputId": "6a78080e-3222-458a-f27c-411fe49e4ce3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/101\n",
      "0/4971\n",
      "tensor(0.9511, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n",
      "OUTPUT\n",
      "tensor([[0.4838, 0.4696, 0.5149, 0.5099, 0.4913, 0.4790, 0.5029, 0.4952, 0.5012,\n",
      "         0.5079, 0.4804, 0.5009, 0.5204, 0.4842, 0.5120, 0.4978, 0.5434, 0.5246,\n",
      "         0.4917, 0.5053, 0.5163, 0.5234, 0.5514, 0.4966, 0.4944, 0.5471, 0.4969,\n",
      "         0.4984],\n",
      "        [0.4728, 0.5197, 0.4955, 0.5219, 0.5130, 0.4826, 0.4413, 0.5256, 0.4734,\n",
      "         0.4729, 0.5070, 0.5177, 0.5137, 0.5115, 0.5223, 0.4514, 0.5361, 0.5240,\n",
      "         0.5152, 0.4704, 0.5070, 0.5685, 0.5505, 0.4916, 0.5377, 0.5158, 0.5162,\n",
      "         0.4592],\n",
      "        [0.4979, 0.5176, 0.5020, 0.5084, 0.4598, 0.4730, 0.4449, 0.5302, 0.4920,\n",
      "         0.4522, 0.4897, 0.5716, 0.5211, 0.5091, 0.5390, 0.5075, 0.4830, 0.5882,\n",
      "         0.5245, 0.5026, 0.5542, 0.5396, 0.6039, 0.5347, 0.5122, 0.5425, 0.4893,\n",
      "         0.5177],\n",
      "        [0.5127, 0.4680, 0.4785, 0.5017, 0.4866, 0.4646, 0.4569, 0.5233, 0.5045,\n",
      "         0.4494, 0.4531, 0.5725, 0.5084, 0.4627, 0.4794, 0.4982, 0.5250, 0.5093,\n",
      "         0.4615, 0.5225, 0.5638, 0.4932, 0.5438, 0.5588, 0.5368, 0.5689, 0.4427,\n",
      "         0.4897],\n",
      "        [0.4972, 0.4822, 0.5108, 0.4789, 0.4847, 0.4938, 0.4802, 0.5135, 0.5037,\n",
      "         0.4896, 0.5047, 0.5345, 0.5204, 0.5145, 0.5190, 0.4782, 0.5477, 0.5446,\n",
      "         0.5085, 0.4985, 0.4898, 0.5335, 0.5505, 0.5423, 0.4747, 0.5633, 0.5069,\n",
      "         0.4926]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "TARGET\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/login1/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:46: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "run_experiment(Args(batch_size=25, epochs=100, optimizer='adam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3635
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2841,
     "status": "error",
     "timestamp": 1538687661053,
     "user": {
      "displayName": "Daniel Borders",
      "photoUrl": "",
      "userId": "03898444674615005606"
     },
     "user_tz": 300
    },
    "id": "2OpAU1x3Y55R",
    "outputId": "fda83c26-a6bf-4034-a2bd-210379da7db5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2517egEvHoM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "080J-JgyuCDF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tD8enmJ0V9CR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of cs482_hw2.ipynb",
   "provenance": [
    {
     "file_id": "1sQFl2FlCn6RHyzIKTwq0_cInuYZKfyNG",
     "timestamp": 1538238759808
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
